from nltk.corpus import wordnet as wn
from nltk.corpus.reader.wordnet import WordNetError
from nltk import word_tokenize, pos_tag   ##implementation of similarity() from http://nlpforhackers.io/wordnet-sentence-similarity/
def penn_to_wn(tag):
    """ Convert between a Penn Treebank tag to a simplified Wordnet tag """
    if tag.startswith('N'):
        return 'n'
 
    if tag.startswith('V'):
        return 'v'
 
    if tag.startswith('J'):
        return 'a'
 
    if tag.startswith('R'):
        return 'r'
 
    return None
 
def tagged_to_synset(word, tag):
    wn_tag = penn_to_wn(tag)
    if wn_tag is None:
        return None
 
    try:
        return wn.synsets(word, wn_tag)[0]
    except:
        return None
def pathsim(ss1, ss2):
    if ss1.path_similarity(ss2) is None:
        return 0
    return ss1.path_similarity(ss2)
def sentence_similarity(sentence1, sentence2):
    """ compute the sentence similarity using Wordnet """
    # Tokenize and tag
    NoneType = type(None)
    sentence1 = pos_tag(word_tokenize(sentence1))
    sentence1nv = []
    sentence2 = pos_tag(word_tokenize(sentence2))
    sentence2nv = []
    # Get the synsets for the tagged words
    synsets1 = []
    count1 = 0
    count2=0
    tup = ()
    synsetnone1 = []
    for tagged_word in sentence1:
        if type(tagged_to_synset(*tagged_word))== NoneType and tagged_word[0][0].isupper() and penn_to_wn(tagged_word[1]) == 'n':
            count1 += 1
            tup = (tagged_word[0], tagged_word[1])
            sentence1nv.append(tup)
            synsetnone1.append(tup)
            continue
        if penn_to_wn(tagged_word[1]) == 'n':
            count1 += 1
            tup = (tagged_word[0], tagged_word[1])
            sentence1nv.append(tup)
    synsets2 = []
    tup = ()
    synsetnone2 = []
    for tagged_word in sentence2:
        if type(tagged_to_synset(*tagged_word))== NoneType and tagged_word[0][0].isupper() and penn_to_wn(tagged_word[1]) == 'n':
            count2+=1
            tup = (tagged_word[0], tagged_word[1])
            sentence2nv.append(tup)
            synsetnone2.append(tup)
            continue
        if penn_to_wn(tagged_word[1]) == 'n':
            count2+=1
            tup = (tagged_word[0], tagged_word[1])
            sentence2nv.append(tup)
    synsets1 = [tagged_to_synset(tagged_word, tag) for tagged_word, tag in sentence1nv]
    synsets2 = [tagged_to_synset(tagged_word, tag) for tagged_word, tag in sentence2nv]
    
    # Filter out the Nones
    synsets1 = [ss for ss in synsets1 if not type(ss) == NoneType]
    synsets2 = [ss for ss in synsets2 if not type(ss) == NoneType]
    score = 0.0
    # For each word in the first sentence
    for synset in synsets1:
        # Get the similarity value of the most similar word in the other sentence
        if not synsets2 == []:
            best_score = max([pathsim(synset, ss) for ss in synsets2])
        # Check that the similarity could have been computed
            if best_score is not None:
                score += best_score
    for synset in synsets2:
        # Get the similarity value of the most similar word in the other sentence
        if not synsets1 == []:
            best_score = max([pathsim(synset, ss) for ss in synsets1])
        # Check that the similarity could have been computed
            if best_score is not None:
                score += best_score
    for synsetnone in synsetnone2:
        if synsetnone in synsetnone1:
            score += 1
    for synsetnone in synsetnone1:
        if synsetnone in synsetnone2:
            score += 1
    # Average the values
    score /= (count1 + count2)
    return score

sentences = [
    "Where can I find information about Sympa?",
    "Where is Dr. Chan's office?",
    "What is Sympa?"
    "Can I view my online courses with my PC?",
    "Can I tell other people my TRACKS pass code?",
    "Do the computer labs offer free softwares?",
    "How to install VPN",
    "Can I forword Florida Tech emails to other email addresses?",
    "How often should I check my email",
    "What kind of files can be attached to my email?",
    "How should I get emails from fitforum?",
    "What is Sympa?",
    "How do I find my Windows address?",
    "How can I activate internet for my dorm room?",
    "What is an ethernet card?",
    "What should I do if items I scan always goes to 'Junk'",
    "My computer is infected by viruses, what should I do?",
    "How can I check my final grades?",
    "What should I do if my laptop is stolen?",
    "buying hardwares for University Use",
    "How do I take a screenshot?",
    "Can I make submissions to the on-line events?",
    "Who can use cloud.fit.edu"
]
 
focus_sentences = ["How do I access my courses online?",
                   "What should I do if someone asks me about my TRACKS password?",
                   "What software is available in university computer labs?",
                   "Installing Fortinet SSL VPN Client",
                   "How do I forward emails from my Florida Tech email address to another email address?",
                   "Do I have to check my Florida Tech email address?",
                   "What is the maximum file size allowed for email attachments?",
                   "How do I subscribe to fitforum?",
                   "Information about Sympa, Florida Tech's List Server.",
                   "How do I find my MAC address?",
                   "When will my dorm room network connection be active?",
                   "What is an ethernet card?",
                   "How can I prevent items I scan to my email from going in the 'Junk' folder?",
                   "What is the best way to protect my computer from viruses, hackers, and malware?",
                   "How do I view my final grades?",
                   "What should I do if my computer is stolen?",
                   "Purchasing Computers for University Use",
                   "How do I take a screenshot?",
                   "How can I submit an on-campus event?",
                   "How do I share folders with cloud.fit.edu"]
for focus_sentence in focus_sentences:
    for sentence in sentences:
        print(sentence_similarity(focus_sentence, sentence))
    print(' ')
